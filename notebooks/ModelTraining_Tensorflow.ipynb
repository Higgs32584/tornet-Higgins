{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936b2c4e-ddf7-4e02-88e3-e280af0f2621",
   "metadata": {},
   "source": [
    "# Training a simple CNN model in Tensorflow for Tornado Detection\n",
    "\n",
    "This notebook steps through how to train a simple CNN model using a subset of TorNet.\n",
    "\n",
    "This will not produce a model with any skill, but simply provides a working end-to-end example of how to set up a data loader, build, and fit a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392369dc-ade9-4d34-8a5f-9d7d7d24a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Uncomment if tornet isn't installed in your environment or in your path already\n",
    "#sys.path.append('../')  \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tornet.data.tf.loader import create_tf_dataset \n",
    "from tornet.data.constants import ALL_VARIABLES\n",
    "import tornet.data.preprocess as pp\n",
    "from tornet.data import preprocess as tfpp\n",
    "import keras\n",
    "from tornet.data.constants import CHANNEL_MIN_MAX\n",
    "import tornet.metrics.keras.metrics as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "188f31eb-e051-4d5f-880d-7ef0a8eddcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic dataloader\n",
    "# This option loads directly from netcdf files, and will be slow and IO bound\n",
    "# To speed up training, either\n",
    "#     build as a tensorflow_dataset , (see tornet/data/tfds/tornet/README.md)\n",
    "#     cache dataset first , or\n",
    "#     use tf.data.Dataset.load on a pre-saved dataset\n",
    "\n",
    "# Location of tornet\n",
    "data_root = \"C:/Users/mjhig/tornet_2013\"\n",
    "\n",
    "# Get training data from 2018\n",
    "data_type='train'\n",
    "years = [2013, 2014,2015,2016,2017,2018]\n",
    "catalog_path = os.path.join(data_root,'catalog.csv')\n",
    "if not os.path.exists(catalog_path):\n",
    "    raise RuntimeError('Unable to find catalog.csv at '+data_root)\n",
    "        \n",
    "catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
    "catalog = catalog[catalog['type']==data_type]\n",
    "catalog = catalog[catalog.start_time.dt.year.isin(years)]\n",
    "catalog = catalog.sample(frac=1,random_state=1234)\n",
    "file_list = [os.path.join(data_root,f) for f in catalog.filename]\n",
    "\n",
    "ds = create_tf_dataset(file_list,variables=ALL_VARIABLES) \n",
    "\n",
    "# (Optional) Save data for faster reloads (makes copy of data!)\n",
    "# ds.save('tornet_sample.tfdataset') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae798b07-9ac5-4784-ba44-cfa242649e46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(catalog_path):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to find catalog.csv at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mdata_root)\n\u001b[1;32m---> 10\u001b[0m catalog \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatalog_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m catalog \u001b[38;5;241m=\u001b[39m catalog[catalog[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mdata_type]\n\u001b[0;32m     12\u001b[0m catalog \u001b[38;5;241m=\u001b[39m catalog[catalog\u001b[38;5;241m.\u001b[39mstart_time\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39misin(years)]\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:320\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_length(names, alldata)\n\u001b[0;32m    318\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[1;32m--> 320\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_date_conversions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_index(date_data, alldata, names)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:822\u001b[0m, in \u001b[0;36mParserBase._do_date_conversions\u001b[1;34m(self, names, data)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_date_conversions\u001b[39m(\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    816\u001b[0m     names: Sequence[Hashable] \u001b[38;5;241m|\u001b[39m Index,\n\u001b[0;32m    817\u001b[0m     data: Mapping[Hashable, ArrayLike] \u001b[38;5;241m|\u001b[39m DataFrame,\n\u001b[0;32m    818\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Sequence[Hashable] \u001b[38;5;241m|\u001b[39m Index, Mapping[Hashable, ArrayLike] \u001b[38;5;241m|\u001b[39m DataFrame]:\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;66;03m# returns data, columns\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m         data, names \u001b[38;5;241m=\u001b[39m \u001b[43m_process_date_conversion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_date_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_date_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_date_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m names, data\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1183\u001b[0m, in \u001b[0;36m_process_date_conversion\u001b[1;34m(data_dict, converter, parse_spec, index_col, index_names, columns, keep_date_col)\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;66;03m# Pyarrow engine returns Series which we need to convert to\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;66;03m# numpy array before converter, its a no-op for other parsers\u001b[39;00m\n\u001b[1;32m-> 1183\u001b[0m     data_dict[colspec] \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolspec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1185\u001b[0m     new_name, col, old_names \u001b[38;5;241m=\u001b[39m _try_convert_dates(\n\u001b[0;32m   1186\u001b[0m         converter, colspec, data_dict, orig_names\n\u001b[0;32m   1187\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1064\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[1;34m(*date_cols)\u001b[0m\n\u001b[0;32m   1061\u001b[0m strs \u001b[38;5;241m=\u001b[39m parsing\u001b[38;5;241m.\u001b[39mconcat_date_cols(date_cols)\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_datetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_datetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tools\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[0;32m   1075\u001b[0m         parsing\u001b[38;5;241m.\u001b[39mtry_parse_dates(strs, dayfirst\u001b[38;5;241m=\u001b[39mdayfirst), cache\u001b[38;5;241m=\u001b[39mcache_dates\n\u001b[0;32m   1076\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1100\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43margc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[0;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\_libs\\tslib.pyx:605\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo)\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DEFAULTPARSER\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:640\u001b[0m, in \u001b[0;36mparser.parse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    637\u001b[0m     default \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mreplace(hour\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, minute\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    638\u001b[0m                                               second\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, microsecond\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 640\u001b[0m res, skipped_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown string format: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, timestr)\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:719\u001b[0m, in \u001b[0;36mparser._parse\u001b[1;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[0;32m    716\u001b[0m     yearfirst \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39myearfirst\n\u001b[0;32m    718\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result()\n\u001b[1;32m--> 719\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[43m_timelex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# Splits the timestr into tokens\u001b[39;00m\n\u001b[0;32m    721\u001b[0m skipped_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# year/month/day list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:201\u001b[0m, in \u001b[0;36m_timelex.split\u001b[1;34m(cls, s)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mcls\u001b[39m, s):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:190\u001b[0m, in \u001b[0;36m_timelex.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 190\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:117\u001b[0m, in \u001b[0;36m_timelex.get_token\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# First character of the token - determines if we're starting\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# to parse a word, a number or something else.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     token \u001b[38;5;241m=\u001b[39m nextchar\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnextchar\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    118\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misnum(nextchar):\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\dateutil\\parser\\_parser.py:206\u001b[0m, in \u001b[0;36m_timelex.isword\u001b[1;34m(cls, nextchar)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misword\u001b[39m(\u001b[38;5;28mcls\u001b[39m, nextchar):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Whether or not the next character is part of a word \"\"\"\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnextchar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misalpha\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build a test set\n",
    "# Basic loader\n",
    "data_type='test'\n",
    "years = [2013, 2014,2015,2016,2017,2018]\n",
    "\n",
    "catalog_path = os.path.join(data_root,'catalog.csv')\n",
    "if not os.path.exists(catalog_path):\n",
    "    raise RuntimeError('Unable to find catalog.csv at '+data_root)\n",
    "        \n",
    "catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
    "catalog = catalog[catalog['type']==data_type]\n",
    "catalog = catalog[catalog.start_time.dt.year.isin(years)]\n",
    "catalog = catalog.sample(frac=1,random_state=1234)\n",
    "file_list = [os.path.join(data_root,f) for f in catalog.filename]\n",
    "\n",
    "ds_test = create_tf_dataset(file_list,variables=ALL_VARIABLES) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3521d09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: {'DBZ': 'DBZ', 'VEL': 'VEL', 'KDP': 'KDP', 'RHOHV': 'RHOHV', 'ZDR': 'ZDR', 'WIDTH': 'WIDTH'}. Received: the structure of inputs={'DBZ': '*', 'VEL': '*', 'KDP': '*', 'RHOHV': '*', 'ZDR': '*', 'WIDTH': '*', 'range_folded_mask': '*', 'label': '*', 'category': '*', 'event_id': '*', 'ef_number': '*', 'az_lower': '*', 'az_upper': '*', 'rng_lower': '*', 'rng_upper': '*', 'time': '*', 'tornado_start_time': '*', 'tornado_end_time': '*', 'coordinates': '*'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - loss: 4.0146\n",
      "Epoch 2/4\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - loss: 1.3025\n",
      "Epoch 3/4\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - loss: 0.9358\n",
      "Epoch 4/4\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - loss: 0.7791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b5d87506d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load and preprocess dataset\n",
    "data_root = \"C:/Users/mjhig/tornet_2013\"\n",
    "data_type = 'train'\n",
    "years = [2013, 2014,2015,2016,2017,2018]\n",
    "\n",
    "\n",
    "catalog_path = os.path.join(data_root, 'catalog.csv')\n",
    "if not os.path.exists(catalog_path):\n",
    "    raise RuntimeError('Unable to find catalog.csv at ' + data_root)\n",
    "\n",
    "catalog = pd.read_csv(catalog_path, parse_dates=['start_time', 'end_time'])\n",
    "catalog = catalog[catalog['type'] == data_type]\n",
    "catalog = catalog[catalog.start_time.dt.year.isin(years)]\n",
    "catalog = catalog.sample(frac=1, random_state=1234)\n",
    "file_list = [os.path.join(data_root, f) for f in catalog.filename]\n",
    "\n",
    "# Create dataset\n",
    "ds = create_tf_dataset(file_list, variables=ALL_VARIABLES)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "ds = ds.map(lambda d: pp.add_coordinates(d, include_az=False, backend=tf))\n",
    "ds = ds.map(pp.remove_time_dim)\n",
    "ds = ds.map(tfpp.split_x_y)\n",
    "ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "ds = ds.batch(32)\n",
    "\n",
    "# Define reusable components\n",
    "def create_model(architecture):\n",
    "    \"\"\"Create a CNN model with different architectures.\"\"\"\n",
    "    inputs = {v: keras.Input(shape=(120, 240, 2), name=v) for v in ALL_VARIABLES}\n",
    "    norm_layers = []\n",
    "    for v in ALL_VARIABLES:\n",
    "        min_max = np.array(CHANNEL_MIN_MAX[v])\n",
    "        var = ((min_max[1] - min_max[0]) / 2) ** 2\n",
    "        var = np.array(2 * [var])\n",
    "        offset = (min_max[0] + min_max[1]) / 2\n",
    "        offset = np.array(2 * [offset])\n",
    "        norm_layers.append(\n",
    "            keras.layers.Normalization(mean=offset, variance=var, name=f'Normalized_{v}')\n",
    "        )\n",
    "    x = keras.layers.Concatenate(axis=-1, name='Concatenate1')(\n",
    "        [l(inputs[v]) for l, v in zip(norm_layers, ALL_VARIABLES)]\n",
    "    )\n",
    "    x = keras.layers.Lambda(lambda x: tf.where(tf.math.is_nan(x), -3.0, x), name='ReplaceNan')(x)\n",
    "    \n",
    "    if architecture == \"baseline\":\n",
    "        x = keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(1, 1, padding='same', activation='relu', name='TornadoLikelihood')(x)\n",
    "    elif architecture == \"deeper\":\n",
    "        x = keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(1, 1, padding='same', activation='relu', name='TornadoLikelihood')(x)\n",
    "    elif architecture == \"residual\":\n",
    "        x = keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x= keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(1, 1, padding='same', activation='relu', name='TornadoLikelihood')(x)\n",
    "    elif architecture == \"wide\":\n",
    "        x = keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Conv2D(1, 1, padding='same', activation='relu', name='TornadoLikelihood')(x)\n",
    "    elif architecture == \"dropout\":\n",
    "        x = keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "        x = keras.layers.Conv2D(1, 1, padding='same', activation='relu', name='TornadoLikelihood')(x)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown architecture type\")\n",
    "    \n",
    "    y = keras.layers.GlobalMaxPool2D(name='GlobalMaxPool')(x)\n",
    "    return keras.Model(inputs=inputs, outputs=y, name=f'TornadoDetector_{architecture}')\n",
    "\n",
    "# Train and evaluate different models\n",
    "architectures = [\"baseline\", \"deeper\", \"residual\", \"wide\", \"dropout\"]\n",
    "results = {}\n",
    "\n",
    "model = create_model(\"dropout\")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss=keras.losses.BinaryCrossentropy(from_logits=True))\n",
    "model.fit(ds, epochs=4, steps_per_epoch=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a3261c-5085-43c9-84bb-febae18daeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "ds_test = ds_test.map(lambda d: pp.add_coordinates(d,include_az=False,backend=tf))\n",
    "ds_test = ds_test.map(pp.remove_time_dim)\n",
    "ds_test = ds_test.map(tfpp.split_x_y)\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "333e21b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: {'DBZ': 'DBZ', 'VEL': 'VEL', 'KDP': 'KDP', 'RHOHV': 'RHOHV', 'ZDR': 'ZDR', 'WIDTH': 'WIDTH'}. Received: the structure of inputs={'DBZ': '*', 'VEL': '*', 'KDP': '*', 'RHOHV': '*', 'ZDR': '*', 'WIDTH': '*', 'range_folded_mask': '*', 'label': '*', 'category': '*', 'event_id': '*', 'ef_number': '*', 'az_lower': '*', 'az_upper': '*', 'rng_lower': '*', 'rng_upper': '*', 'time': '*', 'tornado_start_time': '*', 'tornado_end_time': '*', 'coordinates': '*'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - AUC: 0.5053 - BinaryAccuracy: 0.8407 - loss: 0.6967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6962376236915588, 0.5143358707427979, 0.871874988079071]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "import tornet.metrics.keras.metrics as km\n",
    "metrics = [keras.metrics.AUC(from_logits=True,name='AUC'),\n",
    "           km.BinaryAccuracy(from_logits=True,name='BinaryAccuracy'), \n",
    "           ]\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),metrics=metrics)\n",
    "\n",
    "# steps=10 for demo purposes\n",
    "model.evaluate(ds_test,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bac21ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap_with_input_gradients(model_inputs, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model_inputs)  # Watch the inputs to compute gradients\n",
    "        conv_outputs, predictions = grad_model(model_inputs)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    # Gradients with respect to the inputs\n",
    "    input_grads = tape.gradient(class_channel, model_inputs)\n",
    "\n",
    "    # Gradients with respect to the last conv layer\n",
    "    conv_grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(conv_grads, axis=(0, 1, 2))\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)  # Normalize heatmap to [0, 1]\n",
    "\n",
    "    return np.array(heatmap), input_grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bf7832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: [['DBZ', 'KDP', 'RHOHV', 'VEL', 'WIDTH', 'ZDR']]. Received: the structure of inputs=['*', '*', '*', '*', '*', '*']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input importance: {'DBZ': 3.930369e-07, 'VEL': 5.159255e-06, 'KDP': 3.0089139e-05, 'RHOHV': 2.5846273e-07, 'ZDR': 4.461667e-06, 'WIDTH': 5.2807604e-06}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_gradcam_heatmap_with_input_gradients(model_inputs, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(model_inputs)  # Watch the inputs to compute gradients\n",
    "        conv_outputs, predictions = grad_model(model_inputs)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    # Gradients with respect to the inputs\n",
    "    input_grads = tape.gradient(class_channel, model_inputs)\n",
    "\n",
    "    # Gradients with respect to the last conv layer\n",
    "    conv_grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(conv_grads, axis=(0, 1, 2))  # Average gradients over width and height\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)  # Sum across channels\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)  # ReLU to remove negative values\n",
    "    if tf.reduce_max(heatmap) > 0:\n",
    "        heatmap /= tf.reduce_max(heatmap)  # Normalize heatmap to [0, 1]\n",
    "\n",
    "    return np.array(heatmap), input_grads\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Unpack the dataset\n",
    "for sample in ds_test.take(1):  # Take a single batch from the dataset\n",
    "    inputs, _ = sample  # Assuming the dataset is structured as (features, labels)\n",
    "    break\n",
    "\n",
    "# Prepare the list of inputs for the model\n",
    "model_inputs = [\n",
    "    inputs['DBZ'], \n",
    "    inputs['VEL'], \n",
    "    inputs['KDP'], \n",
    "    inputs['RHOHV'], \n",
    "    inputs['ZDR'], \n",
    "    inputs['WIDTH']\n",
    "]\n",
    "\n",
    "# Generate heatmap and input gradients\n",
    "heatmap, input_grads = make_gradcam_heatmap_with_input_gradients(model_inputs, model, 'TornadoLikelihood')\n",
    "\n",
    "# Calculate the importance of each input\n",
    "input_importance = [tf.reduce_mean(tf.abs(grad)).numpy() for grad in input_grads]\n",
    "\n",
    "# Map input names to their importance\n",
    "input_names = ['DBZ', 'VEL', 'KDP', 'RHOHV', 'ZDR', 'WIDTH']\n",
    "input_importance_dict = dict(zip(input_names, input_importance))\n",
    "\n",
    "# Print or plot the importance of each input\n",
    "print(\"Input importance:\", input_importance_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfce128",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159b9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important regions for DBZ:\n",
      "Shape of importance map: (120, 240)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m6\u001b[39m),edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance Map for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mplot_radar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimportant_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_VARIABLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#plt.imshow(important_regions, cmap=\"hot\")\u001b[39;00m\n\u001b[0;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mjhig\\anaconda3\\envs\\tornet-torch\\lib\\site-packages\\tornet\\display\\display.py:49\u001b[0m, in \u001b[0;36mplot_radar\u001b[1;34m(data, channels, fig, batch_idx, time_idx, sweep_idx, include_cbar, include_title, n_rows, n_cols)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m---> 49\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# grab sample image\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4\u001b[39m: \u001b[38;5;66;03m# no batch\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     batch_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tornet.display.display import plot_radar\n",
    "\n",
    "\n",
    "# Analyze each input slice\n",
    "for i, grad in enumerate(input_grads):\n",
    "    input_name = input_names[i]\n",
    "\n",
    "    # Compute mean absolute gradient for each spatial location\n",
    "    grad_abs_mean = tf.reduce_mean(tf.abs(grad), axis=-1).numpy()  # Shape: (batch_size, height, width)\n",
    "\n",
    "    # Select the most important regions for the first sample in the batch\n",
    "    important_regions = grad_abs_mean[0]  # First sample in batch\n",
    "\n",
    "    print(f\"Most important regions for {input_name}:\")\n",
    "    print(\"Shape of importance map:\", important_regions.shape)\n",
    "\n",
    "    # Visualize the importance map\n",
    "    fig = plt.figure(figsize=(12,6),edgecolor='k')\n",
    "    plt.title(f\"Importance Map for {input_name}\")\n",
    "    plot_radar(data=important_regions,fig=fig,channels=ALL_VARIABLES)\n",
    "    #plt.imshow(important_regions, cmap=\"hot\")\n",
    "    plt.colorbar(label=\"Importance\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tornet-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
